"""Main Streamlit application for RAG QA System."""

import streamlit as st
import logging
from datetime import datetime
from typing import Optional, Dict, Any

from config import get_settings
from contextual_document_processor import ContextualDocumentProcessor
from vector_store import VectorStoreManager
from query_engine import QueryEngine

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Page configuration
st.set_page_config(
    page_title="RAG QA System", page_icon="üìö", layout="wide", initial_sidebar_state="expanded"
)


def initialize_session_state():
    """Initialize Streamlit session state."""
    if "settings" not in st.session_state:
        try:
            st.session_state.settings = get_settings()
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
            st.stop()

    if "vector_store_manager" not in st.session_state:
        st.session_state.vector_store_manager = VectorStoreManager(
            api_key=st.session_state.settings.pinecone_api_key,
            environment=st.session_state.settings.pinecone_environment,
            index_name=st.session_state.settings.pinecone_index_name,
            cohere_api_key=st.session_state.settings.cohere_api_key,
            reranker_top_n=st.session_state.settings.reranker_top_n,
        )

    if "document_processor" not in st.session_state:
        st.session_state.document_processor = ContextualDocumentProcessor(
            max_file_size_mb=st.session_state.settings.max_file_size_mb,
            max_files_count=st.session_state.settings.max_files_count,
            enable_contextual_extraction=st.session_state.settings.enable_contextual_extraction,
        )

    if "query_engine" not in st.session_state:
        st.session_state.query_engine = QueryEngine(
            vector_store_manager=st.session_state.vector_store_manager,
            enable_self_correction=st.session_state.settings.enable_self_correction,
            max_retry_attempts=st.session_state.settings.max_retry_attempts,
        )

    if "documents_loaded" not in st.session_state:
        st.session_state.documents_loaded = False

    if "index_stats" not in st.session_state:
        st.session_state.index_stats = {}


def render_sidebar():
    """Render sidebar with filters and settings."""
    st.sidebar.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–æ–∏—Å–∫–∞")

    # Search parameters
    similarity_top_k = st.sidebar.slider(
        "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (—ç—Ç–∞–ø 1)",
        min_value=10,
        max_value=50,
        value=st.session_state.settings.initial_retrieval_k,
        help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ (–∑–∞—Ç–µ–º reranker –æ—Ç–±–∏—Ä–∞–µ—Ç –ª—É—á—à–∏–µ)",
    )

    similarity_threshold = st.sidebar.slider(
        "–ü–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏",
        min_value=0.0,
        max_value=1.0,
        value=st.session_state.settings.similarity_threshold,
        step=0.1,
        help="–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤",
    )

    Advanced search filters
    st.sidebar.header("üîç –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã")

    Basic filters
    author_filter = st.sidebar.text_input("–ê–≤—Ç–æ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞", placeholder="–í–≤–µ–¥–∏—Ç–µ –∏–º—è –∞–≤—Ç–æ—Ä–∞...")

    Scientific content filters
    st.sidebar.subheader("üìö –ù–∞—É—á–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ")

    has_equations = st.sidebar.checkbox("–°–æ–¥–µ—Ä–∂–∏—Ç —Ñ–æ—Ä–º—É–ª—ã/—É—Ä–∞–≤–Ω–µ–Ω–∏—è")
    has_methodology = st.sidebar.checkbox("–°–æ–¥–µ—Ä–∂–∏—Ç –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—é")
    has_results = st.sidebar.checkbox("–°–æ–¥–µ—Ä–∂–∏—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
    has_abstract = st.sidebar.checkbox("–°–æ–¥–µ—Ä–∂–∏—Ç –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é")

    Content type filters
    st.sidebar.subheader("üìä –¢–∏–ø —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è")

    content_types = st.sidebar.multiselect(
        "–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø—ã —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è",
        ["has_tables", "has_figures", "has_code"],
        format_func=lambda x: {
            "has_tables": "–¢–∞–±–ª–∏—Ü—ã",
            "has_figures": "–†–∏—Å—É–Ω–∫–∏",
            "has_code": "–ö–æ–¥",
        }.get(x, x),
    )

    Complexity filter
    complexity_filter = st.sidebar.selectbox(
        "–£—Ä–æ–≤–µ–Ω—å —Å–ª–æ–∂–Ω–æ—Å—Ç–∏",
        ["–õ—é–±–æ–π", "basic", "intermediate", "advanced"],
        format_func=lambda x: {
            "–õ—é–±–æ–π": "–õ—é–±–æ–π",
            "basic": "–ë–∞–∑–æ–≤—ã–π",
            "intermediate": "–°—Ä–µ–¥–Ω–∏–π",
            "advanced": "–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π",
        }.get(x, x),
    )

    Clear filters button
    if st.sidebar.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å —Ñ–∏–ª—å—Ç—Ä—ã"):
        st.rerun()

    Build metadata filters
    metadata_filters = {}

    if author_filter:
        metadata_filters["author"] = author_filter

    if has_equations:
        metadata_filters["has_equations"] = True

    if has_methodology:
        metadata_filters["has_methodology"] = True

    if has_results:
        metadata_filters["has_results"] = True

    if has_abstract:
        metadata_filters["has_abstract"] = True

    for content_type in content_types:
        metadata_filters[content_type] = True

    if complexity_filter != "–õ—é–±–æ–π":
        metadata_filters["complexity_level"] = complexity_filter

    Store filters in session state
    st.session_state.search_params = {
        "similarity_top_k": similarity_top_k,
        "similarity_threshold": similarity_threshold,
        "metadata_filters": metadata_filters,
    }

    Index statistics
    if st.session_state.index_stats:
        st.sidebar.header("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏–Ω–¥–µ–∫—Å–∞")
        stats = st.session_state.index_stats
        st.sidebar.metric("–í—Å–µ–≥–æ –≤–µ–∫—Ç–æ—Ä–æ–≤", stats.get("total_vectors", 0))
        st.sidebar.metric("–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å", stats.get("dimension", 0))
        if stats.get("index_fullness"):
            st.sidebar.metric("–ó–∞–ø–æ–ª–Ω–µ–Ω–Ω–æ—Å—Ç—å", f"{stats['index_fullness']:.1%}")

    Query statistics
    query_stats = st.session_state.query_engine.get_statistics()
    if query_stats["total_queries"] > 0:
        st.sidebar.header("üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤")
        st.sidebar.metric("–í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤", query_stats["total_queries"])
        st.sidebar.metric("–£—Å–ø–µ—à–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã", query_stats["successful_queries"])

        if query_stats.get("self_corrected_queries", 0) > 0:
            st.sidebar.metric("–°–∞–º–æ–∫–æ—Ä—Ä–µ–∫—Ü–∏—è", f"{query_stats['correction_rate']:.1f}%")
            st.sidebar.metric("–°—Ä–µ–¥–Ω–µ–µ —á–∏—Å–ª–æ –ø–æ–ø—ã—Ç–æ–∫", query_stats["avg_retry_count"])

        if query_stats["language_distribution"]:
            st.sidebar.write("**–Ø–∑—ã–∫–∏ –∑–∞–ø—Ä–æ—Å–æ–≤:**")
            for lang, count in query_stats["language_distribution"].items():
                st.sidebar.write(f"- {lang}: {count}")

    Enhanced features status
    st.sidebar.header("üöÄ –ê–∫—Ç–∏–≤–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è")

    if st.session_state.settings.enable_self_correction:
        st.sidebar.success("‚úÖ –°–∞–º–æ–∫–æ—Ä—Ä–µ–∫—Ü–∏—è –≤–∫–ª—é—á–µ–Ω–∞")
    else:
        st.sidebar.warning("‚ùå –°–∞–º–æ–∫–æ—Ä—Ä–µ–∫—Ü–∏—è –æ—Ç–∫–ª—é—á–µ–Ω–∞")

    if st.session_state.vector_store_manager.reranker:
        st.sidebar.success("‚úÖ Cohere Reranker –∞–∫—Ç–∏–≤–µ–Ω")
    else:
        st.sidebar.warning("‚ùå Reranker –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")

    if st.session_state.settings.enable_contextual_extraction:
        st.sidebar.success("‚úÖ –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∫–ª—é—á–µ–Ω–∞")
    else:
        st.sidebar.warning("‚ùå –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–∫–ª—é—á–µ–Ω–∞")


def render_document_upload():
    """Render document upload section."""
    st.header("üìÑ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

    uploaded_files = st.file_uploader(
        "–í—ã–±–µ—Ä–∏—Ç–µ PDF —Ñ–∞–π–ª—ã",
        type=["pdf"],
        accept_multiple_files=True,
        help=f"–ú–∞–∫—Å–∏–º—É–º {st.session_state.settings.max_files_count} —Ñ–∞–π–ª–æ–≤, –¥–æ {st.session_state.settings.max_file_size_mb}MB –∫–∞–∂–¥—ã–π",
    )

    if uploaded_files:
        st.write(f"**–í—ã–±—Ä–∞–Ω–æ —Ñ–∞–π–ª–æ–≤:** {len(uploaded_files)}")

        Show file details
        for file in uploaded_files:
            file_size_mb = file.size / (1024 * 1024)
            st.write(f"- {file.name} ({file_size_mb:.1f}MB)")

        if st.button("üöÄ –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã", type="primary"):
            with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤..."):
                Process documents
                documents = st.session_state.document_processor.process_uploaded_files(
                    uploaded_files
                )

                if documents:
                    st.success(f"–£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")

                    Show extraction stats
                    if hasattr(st.session_state.document_processor, "get_extraction_stats"):
                        stats = st.session_state.document_processor.get_extraction_stats()
                        if stats["contextual_extraction_enabled"]:
                            st.info(
                                f"üß† –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞: {stats['available_extractors']} —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–æ–≤ –∞–∫—Ç–∏–≤–Ω–æ"
                            )

                    Initialize or create index
                    with st.spinner("–°–æ–∑–¥–∞–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞..."):
                        if not st.session_state.vector_store_manager.create_index():
                            st.error("–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω–¥–µ–∫—Å–∞ Pinecone")
                            return

                        if not st.session_state.vector_store_manager.create_vector_index(documents):
                            st.error("–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞")
                            return

                    st.session_state.documents_loaded = True
                    st.session_state.index_stats = (
                        st.session_state.vector_store_manager.get_index_stats()
                    )

                    Show success with feature info
                    success_msg = "–î–æ–∫—É–º–µ–Ω—Ç—ã —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω—ã!"
                    if st.session_state.vector_store_manager.reranker:
                        success_msg += " üéØ –ò–Ω–¥–µ–∫—Å –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!"
                    st.success(success_msg)
                    st.rerun()
                else:
                    st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã")


def render_query_interface():
    """Render query interface."""
    st.header("ü§ñ –ü–æ–∏—Å–∫ –∏ –≤–æ–ø—Ä–æ—Å—ã")

    if not st.session_state.documents_loaded:
        Try to load existing index
        if st.session_state.vector_store_manager.load_existing_index():
            st.session_state.documents_loaded = True
            st.session_state.index_stats = st.session_state.vector_store_manager.get_index_stats()
        else:
            st.warning("–°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏")
            return

    Query input
    query = st.text_area(
        "–ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞–º:",
        placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: –ß—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç—Å—è –æ –º–∞—à–∏–Ω–Ω–æ–º –æ–±—É—á–µ–Ω–∏–∏ –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö?",
        height=100,
    )

    col1, col2 = st.columns([3, 1])

    with col1:
        search_button = st.button("üîç –ù–∞–π—Ç–∏ –æ—Ç–≤–µ—Ç", type="primary", disabled=not query.strip())

    with col2:
        if st.button("üóëÔ∏è –û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é"):
            st.session_state.query_engine.clear_history()
            st.success("–ò—Å—Ç–æ—Ä–∏—è –æ—á–∏—â–µ–Ω–∞")
            st.rerun()

    if search_button and query.strip():
        with st.spinner("–ü–æ–∏—Å–∫ –æ—Ç–≤–µ—Ç–∞..."):
            result = st.session_state.query_engine.process_query(
                query=query, **st.session_state.search_params
            )

        if result["success"]:
            Display answer
            st.subheader("üí° –û—Ç–≤–µ—Ç")
            st.write(result["answer"])

            Display self-correction info
            if result.get("self_corrected", False):
                st.success(
                    f"üîÑ –û—Ç–≤–µ—Ç —É–ª—É—á—à–µ–Ω —á–µ—Ä–µ–∑ —Å–∞–º–æ–∫–æ—Ä—Ä–µ–∫—Ü–∏—é (–ø–æ–ø—ã—Ç–æ–∫: {result.get('retry_count', 0)})"
                )

            Display processing info
            col1, col2 = st.columns(2)
            with col1:
                st.info(f"üìä –ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –Ω–∞–π–¥–µ–Ω–æ: {len(result['sources'])}")
            with col2:
                if result.get("self_corrected", False):
                    st.info(f"üéØ –°–∞–º–æ–∫–æ—Ä—Ä–µ–∫—Ü–∏—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∞")
                else:
                    st.info(f"‚úÖ –û—Ç–≤–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω —Å –ø–µ—Ä–≤–æ–π –ø–æ–ø—ã—Ç–∫–∏")

            Display sources
            if result["sources"]:
                st.subheader("üìö –ò—Å—Ç–æ—á–Ω–∏–∫–∏")
                for source in result["sources"]:
                    with st.expander(
                        f"üìÑ {source['filename']} (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {source['score']:.2f})"
                    ):
                        st.write(f"**–ó–∞–≥–æ–ª–æ–≤–æ–∫:** {source['title']}")
                        st.write(f"**–ê–≤—Ç–æ—Ä:** {source['author']}")
                        st.write(f"**–§—Ä–∞–≥–º–µ–Ω—Ç —Ç–µ–∫—Å—Ç–∞:**")
                        st.write(source["text_snippet"])
        else:
            st.error(f"–û—à–∏–±–∫–∞: {result.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")


def render_query_history():
    """Render query history."""
    st.header("üìã –ò—Å—Ç–æ—Ä–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤")

    history = st.session_state.query_engine.get_query_history()

    if not history:
        st.info("–ò—Å—Ç–æ—Ä–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤ –ø—É—Å—Ç–∞")
        return

    for i, item in enumerate(reversed(history[-5:])):  # Show last 5
        with st.expander(f"‚ùì {item['query'][:50]}... ({item['timestamp'][:19]})"):
            st.write(f"**–í–æ–ø—Ä–æ—Å:** {item['query']}")
            st.write(f"**–û—Ç–≤–µ—Ç:** {item['answer']}")
            st.write(f"**–Ø–∑—ã–∫:** {item['language']}")
            st.write(f"**–ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤:** {len(item['sources'])}")
            if item.get("self_corrected", False):
                st.write(f"**–°–∞–º–æ–∫–æ—Ä—Ä–µ–∫—Ü–∏—è:** ‚úÖ (–ø–æ–ø—ã—Ç–æ–∫: {item.get('retry_count', 0)})")
            else:
                st.write(f"**–°–∞–º–æ–∫–æ—Ä—Ä–µ–∫—Ü–∏—è:** ‚ùå")


def main():
    """Main application function."""
    st.title("üìö RAG QA System")
    st.markdown("–°–∏—Å—Ç–µ–º–∞ –≤–æ–ø—Ä–æ—Å–æ–≤ –∏ –æ—Ç–≤–µ—Ç–æ–≤ –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –∫–æ–º–∞–Ω–¥")

    Initialize session state
    initialize_session_state()

    Render sidebar
    render_sidebar()

    Main content
    tab1, tab2, tab3 = st.tabs(["üìÑ –î–æ–∫—É–º–µ–Ω—Ç—ã", "üîç –ü–æ–∏—Å–∫", "üìã –ò—Å—Ç–æ—Ä–∏—è"])

    with tab1:
        render_document_upload()

    with tab2:
        render_query_interface()

    with tab3:
        render_query_history()


if __name__ == "__main__":
    main()
